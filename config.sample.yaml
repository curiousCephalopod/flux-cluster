---
# (Required) Distribution can either be k3s, k0s, or talos
distribution: ""

# (Required) IANA formatted timezone (e.g. America/New_York)
timezone: ""

# (Required) Cluster details
cluster:
  # schematics:
  #   # (Required) Disabling the schematic will disable the system-upgrade-controller and any
  #   #   additional Talos customization you have defined.
  #   enabled: false
  #   # (Required) For use with the system-upgrade-controller generate a schematic ID
  #   #   based on your System Extension requirements https://factory.talos.dev/
  #   id: ""
  #   # (Required) Additional NodeConfigs to apply to all nodes
  #   #   See: https://budimanjojo.github.io/talhelper/latest/reference/configuration/#nodeconfigs
  #   customization: |-
  #     extraKernelArgs:
  #       - net.ifnames=0
  #     systemExtensions:
  #       officialExtensions:
  #         - siderolabs/intel-ucode
  #         - siderolabs/i915-ucode
  # # (Optional) Add vlan tag to network master device
  # #   See: https://www.talos.dev/latest/advanced/advanced-networking/#vlans
  # vlan: 1
  # (Required) Cluster name
  name: ""
  # (Required) Talos API endpoint
  endpoint: ""
  # (Required) The nodes section is used to configure your cluster nodes
  nodes:
    # (Required) CIDR your nodes are on (e.g. 192.168.1.0/24)
    host_network: ""
    # (Required) The DNS server to use for the cluster, this can be an existing
    #   local DNS server or a public one
    # If using a local DNS server make sure it meets the following requirements:
    #   1. your nodes can reach it
    #   2. it is configured to forward requests to a public DNS server
    #   3. you are not force redirecting DNS requests to it - this will break cert generation over DNS01
    # If using multiple DNS servers make sure they are setup the same way,
    #   there is no guarantee that the first DNS server will be used.
    dns_servers:
      - "1.1.1.1"
    # (Required) Cluster NTP server
    ntp: ""
    # (Optional) The DNS search domain to use for the nodes.
    # Leave this option blank to avoid possible DNS issues inside the cluster.
    search_domain: ""
    # (Required) Use only 1, 3 or more ODD number of controller nodes, recommended is 3
    #   Worker nodes are optional
    inventory: []
      # - name: ""               # Name of the node (must match [a-z0-9-\.]+)
      #   address: ""            # IP address of the node
      #   controller: true       # (Required) Set to true if this is a controller node
      #   talos_disk_device: ""  # (Required: Talos) Device Path or Serial number of Disk for this node
      #   talos_patches: ""      # Talos device specific patches
      # ...
  # (Required) The pod CIDR for the cluster, this must NOT overlap with any
  #   existing networks and is usually a /16 (64K IPs).
  # If you want to use IPv6 check the advanced flags below
  pod_network: 10.69.0.0/16
  # (Required) The service CIDR for the cluster, this must NOT overlap with any
  #   existing networks and is usually a /16 (64K IPs).
  # If you want to use IPv6 check the advanced flags below
  service_network: 10.96.0.0/16
  # (Required) The IP address of the Kube API, choose an available IP in
  #   your nodes host network that is NOT being used. This is announced over L2.
  endpoint_vip: ""
  # (Optional) Add additional SANs to the Kube API cert, this is useful
  #   if you want to call the Kube API by hostname rather than IP
  tls_sans: []

# (Required) Flux details
# IMPORTANT: All options are ignored if flux is disabled and no resources
#   outside Cilium and kube-vip (k0s/k3s) will be deployed to your cluster.
flux:
  # (Required) Disable to use a different tool (e.g. kubectl, Argo, Kluctl)
  enabled: true
  # (Required) Options for Github
  github:
    # (Required) Github repository URL (for private repos use the ssh:// URL)
    address: ""
    # (Required) Github repository branch
    branch: main
    # (Required) Private key for Flux to access the GitHub repository
    private:
      # (Required) Enable to use a private GitHub repository
      enabled: false
      # Private key for Flux to access the GitHub repository
      #   1. Generate a new key with the following command:
      #      > ssh-keygen -t ecdsa -b 521 -C "github-deploy-key" -f github-deploy.key -q -P ""
      #   2. Make sure to paste public key from "github-deploy.key.pub" into
      #      the deploy keys section of your repository settings.
      #   3. Uncomment and paste the private key below
      # key: |
      #   -----BEGIN OPENSSH PRIVATE KEY-----
      #   ...
      #   -----END OPENSSH PRIVATE KEY-----
  # (Required) Age Public Key (e.g. age15uzrw396e67z9wdzsxzdk7ka0g2gr3l460e0slaea563zll3hdfqwqxdta)
  sops_age_public_key: ""

# (Required) Host domain
physical_domain: ""
# (Required) Image mirrors domain
mirrors_domain: ""
# (Required) Cluster domain
cluster_domain: ""

# (Required) CA chain to trust (single line, with escaped newlines like \\n)
ca_chain: ""

# (Required) CertManager certificates
certmanager:
  tls:
    # (Required) Local CA Issuer certificate, with chain
    crt: ""
    # (Required) Local CA Issuer key
    key: ""

# (Optional) Feature gates are used to enable experimental features
feature_gates:
  # Enable Dual Stack IPv4 first
  # IMPORTANT: I am looking for people to help maintain IPv6 support since I cannot test it.
  #   Ref: https://github.com/onedr0p/flux-cluster-template/issues/1148
  # Keep in mind that Cilium does not currently support IPv6 L2 announcements.
  # Make sure you set cluster.pod_cidr and cluster.service_cidr
  #   to a valid dual stack CIDRs, e.g. "10.42.0.0/16,fd00:10:244::/64"
  dual_stack_ipv4_first: false
